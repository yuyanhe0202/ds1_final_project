---
title: "Final Project"
author: "He_Huang_Yang_Yu"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
execute:
  warning: false
  message: false
embed-resources: true
---

# Background

China is experiencing rapid population aging, raising concerns about how to assess and anticipate health risks among middle-aged and older adults. Although health conditions can be measured through surveys or clinical assessments, these approaches are often time-consuming and costly to implement at scale. This motivates a practical question for policy: can individual health risk be reasonably inferred from information that is routinely observable in survey or administrative settings, such as demographic characteristics, socioeconomic conditions, and regional context? Self-rated health (SRH) is well-suited for this purpose because it captures not only perceived physical health but also broader living conditions and well-being. In the Chinese context, SRH has been shown to be a reliable and meaningful indicator, with consistent associations with objective health measures (Qi, 2014), and prior studies using the China Health and Retirement Longitudinal Study (CHARLS) have documented systematic determinants of SRH across demographic and socioeconomic groups (Zhang et al., 2021).

Using data from the 2018 wave of CHARLS, this project adopts a predictive approach to examine SRH among middle-aged and older adults in China (Zhao et al., 2020). Our central research question is: which individual characteristics are most important for predicting self-reported health, and how well can overall health status be predicted using variables that are commonly available in survey or administrative data? This framing aligns with recent work that uses machine learning to predict SRH and interpret the relative importance of predictors to inform health equity and resource planning (Clark et al., 2021).

Building on these descriptive patterns, we apply supervised machine learning methods to predict SRH using demographic, socioeconomic, and healthcare-access-related variables, and compare models using out-of-sample performance metrics. This allows us to evaluate both predictive accuracy and the relative contribution of different types of predictors, consistent with the interpretability-oriented ML approach in prior SRH prediction research (Clark et al., 2021). From a policy perspective, our goal is not clinical diagnosis, but rather to assess whether readily available information can help identify higher-risk populations efficiently, supporting more timely health planning and resource allocation in an aging society.

# Data Source and Outcome Definition

The analysis uses data from the 2018 wave of CHARLS, a nationally representative survey of Chinese residents generally aged 45 and above. CHARLS employs a stratified, multi-stage probability sampling design and provides survey weights to ensure representativeness of the target population (Zhao et al., 2020). The 2018 wave covers 28 provinces in China, excluding Ningxia, Tibet, and Hainan from the sampling frame. We also merge province-level GDP and healthcare resource indicators from the National Bureau of Statistics of China to incorporate regional economic and healthcare context (NBS, 2018).

We focus on the 2018 wave rather than the 2020 wave because the latter coincides with the COVID-19 pandemic, during which SRH may reflect short-term system-wide shocks rather than baseline health perceptions. Using 2018 data allows us to examine SRH under relatively stable social and health-system conditions (Zhao et al., 2023).

The outcome of interest is SRH, measured by the CHARLS survey variable da002. Respondents rate their overall health on a five-point ordinal scale (very good, good, fair, poor, very poor). This measure captures individuals’ subjective assessment of general health and is widely used in aging and population health research; in China, SRH has also been shown to have strong validity relative to objective health indicators (Qi, 2014). For classification modeling purpose, da002 is also transformed into a binary outcome that classifies respondents into good versus bad health, consistent with common practice in SRH prediction studies that prioritize interpretability and policy-relevant classification (Clark et al., 2021).

# Variable selection rationale

The objective of this analysis is to predict SRH in a way that is informative for public resource allocation rather than detailed household-level diagnosis. From a central-government perspective, the goal is to assess health needs without relying solely on costly and time-intensive surveys. Accordingly, the model relies on general demographic and socioeconomic characteristics that are routinely collected through administrative systems and are plausibly correlated with health outcomes. These include age, gender, marital status, living area (urban–rural classification), employment and retirement status, income and pension receipt, health insurance coverage, and number of children. These variables reflect key life-course, labor market, and institutional dimensions that shape health risk and access to care, and they are also consistent with prior empirical work on SRH determinants in older populations (Zhang et al., 2021). In addition, our emphasis on widely observable predictors is aligned with ML-based SRH research that evaluates how standard demographic and socioeconomic features contribute to prediction performance and interpretability (Clark et al., 2021).

To capture regional differences in healthcare supply, we also incorporate province-level health resource indicators, specifically the number of hospitals and healthcare professionals per 10,000 population (NBS, 2018). These measures allow the model to reflect structural variation in access to healthcare across provinces, above and beyond individual-level characteristics.

# Data cleaning and variable construction

The raw CHARLS 2018 data were cleaned and transformed into a model ready dataset suitable for machine learning workflows. Variables imported with survey value labels were converted to appropriate formats to avoid unintended numeric interpretations. Categorical variables such as living area and marital status were converted to factor variables using their original survey labels, ensuring they were treated as nominal predictors during modeling. Binary survey responses, such as employment status and income receipt, were recoded into consistent 0 and 1 indicators based on documented response categories (Zhao et al., 2020).

To maintain transparency and reproducibility, we preserved original variables where needed and created transformed variables explicitly rather than overwriting the raw fields. This preprocessing strategy ensured compatibility with standard modeling pipelines, including dummy variable generation for categorical predictors and consistent handling of missingness and invalid values.

1.  Import data, select variables, convert to variables, cleaning variables

```{r}
#install.packages("remotes")
#remotes::install_github("GuangchuangYu/chinamap")
library(tidyverse)
library(tidymodels)
library(vip)
library(chinamap)
library(readxl)

load("data/Final_2018Merged.RData")

# da002: Self-Reported Health Status
# cd001_w4_1_: Who Live with XConParName[1]
# be002: Have a Partner Living Together
# bb001_w3_2: Location of Residential Address
# be001: Marital Status
# bf006_w4_5_1: The Number of Children Under 18
# bg002_w4: Religious Beliefs
# fa002_w4: Nonfarm Work (for at Least One Hour Last Month) or Not
# ga001: Receive Wage and Bonus Income
# ga002: How Much Receive
# fn002_w4: Receive/Participate Government/Institutions/Firm Pension
# ha000_w4_0: Number of Houses
# ea001_w4_s12: No Medical Insurance
# cb050_w3: Number of Children
# hosp_10k: Number of hospitals per 10k population
# staff_10k: Number of health professionals per 10,000 population


# select only the variables needed
data <- Final_2018Merged |>
  select(ID, da002, ba000_w2_3, ba004_w3_1, cd001_w4_1_, bb001_w3_2, be001, bf006_w4_5_1, bg002_w4, fa002_w4, ga001, ga002, fn002_w4, ha000_w4_0, ea001_w4_s12, cb050_w3, hosp_10k, staff_10k, INDV_weight_ad2, province) |>
  filter(!is.na(da002)) |>
  mutate(living_area = haven::as_factor(bb001_w3_2)) |>
  mutate(marital_status = haven::as_factor(be001)) |>
  mutate(male = case_when(
    as.numeric(ba000_w2_3) == 1 ~ 1,
    as.numeric(ba000_w2_3) == 2 ~ 0)) |>
  mutate(age = 2018 - ba004_w3_1) |>
  mutate(bg002_w4 = case_when(
    as.numeric(bg002_w4) == 1 ~ 1,
    as.numeric(bg002_w4) == 2 ~ 0)) |>
  mutate(fa002_w4 = case_when(
    as.numeric(fa002_w4) == 1 ~ 1,
    as.numeric(fa002_w4) == 2 ~ 0)) |>
  mutate(ga001 = case_when(
    as.numeric(ga001) == 1 ~ 1,
    as.numeric(ga001) == 2 ~ 0)) |>
  mutate(fn002_w4 = case_when(
    as.numeric(fn002_w4) == 1 ~ 1,
    as.numeric(fn002_w4) == 2 ~ 0)) |>
  mutate(ea001_w4_s12 = case_when(
    as.numeric(ea001_w4_s12) == 0 ~ 1,
    as.numeric(ea001_w4_s12) == 12 ~ 0)) |>
  mutate(health_cat = case_when(
    as.numeric(da002) == 1 ~ "good",
    as.numeric(da002) == 2 ~ "good",
    as.numeric(da002) == 3 ~ "bad",
    as.numeric(da002) == 4 ~ "bad",
    as.numeric(da002) == 5 ~ "bad"))

```

# Machine learning methodology

To investigate the research question, which individual characteristics are most important for predicting self-rated health and how well health status can be predicted using commonly available variables, we implemented a machine learning workflow that incorporated individual survey weights to improve national representativeness (Zhao et al., 2020). The data were split into an 80 percent training set and a 20 percent test set. Model tuning and model selection were conducted using cross validation on the training set, and final performance was assessed on the held-out test set to reduce the risk of overfitting (Choi & Jung, 2025).

[*Why LASSO and Random Forest*]{.underline}

We focused on two complementary methods, LASSO and Random Forest, because they align with both components of our research question, prediction performance and interpretability.

First, LASSO provides an interpretable baseline model with built in feature selection. By shrinking weaker coefficients toward zero, it highlights a smaller set of predictors that contribute most to prediction, which directly supports our goal of identifying the most informative individual characteristics (Clark et al., 2021; Choi & Jung, 2025).

Second, Random Forest captures nonlinear relationships and interactions that are likely present in subjective health assessments, while also providing model-based measures of variable importance. This allows us to compare not only predictive accuracy but also the ranking of key predictors under a flexible nonparametric model (Clark et al., 2021; Choi & Jung, 2025).

Both methods have been used in prior work to predict self-rated health and related outcomes, and the literature highlights their complementary strengths, transparency and feature selection for LASSO, and strong predictive performance and importance ranking for Random Forest (Clark et al., 2021; Choi & Jung, 2025).

[*Regression and classification frameworks*]{.underline}

We evaluated both a regression framework and a classification framework.

1.  Regression framework

We treated the original five category SRH measure as an ordinal numeric outcome and fit models that predict SRH on its original scale, then evaluated performance using RMSE.

2.  Classification framework

Following common practice in SRH prediction research that uses binary thresholds to improve interpretability and reduce ambiguity, we recoded SRH into a binary good versus bad outcome (Clark et al., 2021; Choi & Jung, 2025).

2.0 Get data

```{r}
set.seed(0202)

# Get the clean data, remove redundant variables, call weighting
data_clean <- data %>%
  mutate(weight_idv = importance_weights(INDV_weight_ad2)) |>
  select(-bb001_w3_2, -be001, -ba000_w2_3, -ba004_w3_1, -ID, -INDV_weight_ad2) |>
  filter(!is.na(weight_idv))

## Split data
data_split <- initial_split(data = data_clean, prop = 0.8)
data_train <- training(x = data_split)
data_test <- testing(x = data_split)

```

2.0 Continued: Exploratory Data Analysis: presenting China economic status and health status

```{r}
# 1. China GDP by province 
# GDP information is not from the dataset we use; just to present a general idea of China's economic status
## read GDP file, merge into map
GDP <- read_excel("data/GDP.xls", sheet = "Sheet1")

cn <- get_map_china()

cn_gdp <- cn |>
  left_join(GDP, by = "province")

## map
ggplot(cn_gdp,
                aes(x = long, y = lat, group = group, fill = gdp_2018)) +
  geom_polygon(color = "black", linewidth = 0.2) + 
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),
    na.value = "grey90",
    name = "GDP in 2018"
  ) +
  labs(
    title = "Each province's GDP in 2018"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_gdp.png")

# 2. distribution of individual income
## select a series of individual income variables
income_vars <- c("ga002")

## extract these values about individual annual income
income_mat <- data_train[, income_vars]

## For each sample, sum the income to obtain the total personal income.
person_income <- rowSums(as.matrix(income_mat), na.rm = TRUE)

## calculate annual individual income by province
prov_income <- data_train |>
  mutate(person_income = person_income) |>
  group_by(province) |>
  summarise(
    mean_income = mean(person_income, na.rm = TRUE),
    .groups = "drop"
  )

## merge data into China map
cn_income <- cn |>
  left_join(prov_income, by = "province")

## map of annual individual income by province
ggplot(cn_income,
       aes(x = long, y = lat, group = group, fill = mean_income)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),  # red~low, high~green
    na.value = "grey90",
    name = "Average annual individual income"
  ) +
  labs(
    title = "Average annual individual income in each province in 2018"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_income.png")

# 3. average self-reported health status by province

## Change da002 from haven_labelled to numeric
data_train <- data_train |>
  mutate(
    province = recode(
      province,
      "北京"   = "北京市",
      "广西省" = "广西壮族自治区"  #manually change 2 names into official ones
    )
  )

##. Calculate the mean of da002 by province
prov_da <- data_train |>
  group_by(province) |>
  summarise(
    da002_mean = mean(da002, na.rm = TRUE)
  ) |>
  ungroup()

## merge province-level data into China map
cn_da <- cn |>
  left_join(prov_da, by = "province")

## map of average da002 among all provinces
ggplot(cn_da,
            aes(x = long, y = lat, group = group, fill = da002_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("darkgreen", "yellow", "red"),  #red~low, high~green
    na.value = "grey90"
  ) +
  labs(
    title = "Average self-reported health in each province（da002）",
    fill  = "Average self-reported health (da002)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_health.png")

```

2.1 Using regression pipelines

```{r}
# create a recipe
data_rec <- 
  recipe(da002 ~ ., data = data_train) %>%
  step_rm(health_cat, province) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

# v-fold: using this folds for all remaining models
folds <- vfold_cv(data = data_train, v = 10, repeats = 1)

# Lasso prediction
## create a tuning grid for lasso regularization, varying the regularization penalty
lasso_grid <- grid_regular(penalty(), levels = 10)

## Lasso specification
lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet")

## Lasso workflow
lasso_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lasso_mod) %>%
  add_case_weights(weight_idv)

## fit
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

## Calculate RMSE
lasso_rmse <- lasso_cv %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "rmse")

## Plot RMSE
lasso_rmse |>
  group_by(id) |>
  summarize(RMSE = mean(.estimate)) |>
  ggplot(aes(x = id, y = RMSE)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "RMSE",
    title = "Lasso RMSE Across Penalty Values"
  ) +
  theme_minimal()

## Mean RMSE across 10 folds
mean(lasso_rmse$.estimate)


# ----------Random Forest prediction--------------
rf_mod <- rand_forest() |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

## Random forest workflow
rf_wf <- workflow() |>
  add_recipe(data_rec) |>
  add_model(rf_mod) |>
  add_case_weights(weight_idv)

## fit
rf_resamples <- rf_wf |>
  fit_resamples(resamples = folds)

## Calculate RMSE
rf_rmse <- rf_resamples %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "rmse")

## Plot RMSE
rf_rmse |>
  ggplot(aes(x = id, y = .estimate)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "RMSE",
    title = "Random Forest RMSE Across Penalty Values"
  ) +
  theme_minimal()

## Mean RMSE across 10 folds
mean(rf_rmse$.estimate)


# --------Model choose, final fit and check variable importance
# Random Forest model has the lower RMSE in the regression approach; 
# we would therefore check the best fit model using the RF model

## select the best model based on the "rmse" metric
rf_best <- rf_resamples %>%
  select_best(metric = "rmse")

# finalize random forest workflow and the best model 
rf_final <- finalize_workflow(rf_wf, rf_best) %>% 
  fit(data = data_train)

## important predictors for rf model
rf_final |>
  extract_fit_parsnip() |>
  vip() + 
  labs(title = "Variable Importance: Random Forest Model") +
  theme_minimal()

ggsave(filename = "graph/importance_rf.png")

```

2.2 Using classification pipelines

```{r}
# Treat health status as bad and good
# create a new recipe
data_rec_cat <- 
  recipe(health_cat ~ ., data = data_train) %>%
  step_rm(da002, province) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

# --------Lasso specification------
lasso_mod_cat <- multinom_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

## Lasso workflow
lasso_wf_cat <- workflow() %>%
  add_recipe(data_rec_cat) %>%
  add_model(lasso_mod_cat) %>%
  add_case_weights(weight_idv)

## fit
lasso_cv_cat <- lasso_wf_cat %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

## check accuracy
lasso_acc <- lasso_cv_cat %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy")

## Plot accuracy
lasso_acc |>
  group_by(id) |>
  summarize(accuracy = mean(.estimate)) |>
  ggplot(aes(x = id, y = accuracy)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "accuracy",
    title = "Lasso Accuracy Across Penalty Values"
  ) +
  theme_minimal()

mean(lasso_acc$.estimate)

# --------Random forest-----------
## Random Forest model call
rf_mod_cat <- rand_forest() |>
  set_mode(mode = "classification") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

## workflow
rf_wf_cat <- workflow() |>
  add_recipe(data_rec_cat) |>
  add_model(rf_mod_cat) |>
  add_case_weights(weight_idv)

## fit
rf_resamples_cat <- rf_wf_cat |>
  fit_resamples(resamples = folds)

## Calculate accuracy
rf_acc <- rf_resamples_cat %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy")

## Plot accuracy
rf_acc |>
  ggplot(aes(x = id, y = .estimate)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "Accuracy",
    title = "Random Forest Accuracy Across Penalty Values"
  ) +
  theme_minimal()

## Mean Accuracy across 10 folds
mean(rf_acc$.estimate)

```

# Final model choose

Random Forest has better performance across regression and classification pipeline.In the Regression task, where we kept the full 5-point scale, the Random Forest was the winner, achieving a lower average RMSE. In the Classification task, the results are very similar across the two models; the Random Forest model yielded slightly higher accuracy of 75%.

Originally, the health status was set to 3 classes, good, fair and bad. And running for 3 classes, both models generated accuracy around 50% which is basically like flipping a coin. We then updated the middle category to bad, which reflects a Chinese habit where "Fair" is often a polite proxy for "Not Good", and the performance improved consequently. However, we have to consider the 'cost' of that improvement in accuracy: classification requires us to set a subjective threshold for what counts as 'good' or 'bad' health. This can introduce bias and hide nuances in the data. 

Therefore, to maintain the most objective and robust estimation of health, we selected Random Forest with Regression mode as our final model for evaluation against the test dataset. We fitted the final model to the test data and we got similar RMSE, which proves the robustness of the model.

After fitting the test data, we generated similar RMSE as in the training data, indicating robustness of the final model. 

3.  Fit the final model, check result

```{r}
# fit on test data
test_pred <- predict(rf_final, data_test)

# getting rmse
test_pred <- data_test %>%
  select(da002) %>%
  bind_cols(test_pred)

rmse(test_pred, truth = da002, estimate = .pred)

```

## Deep-dive into the final model

After selecting the Random Forest regression as our final model, we examined variable importance to understand which predictors contributed most to SRH prediction. Age and province level healthcare resources emerged as leading predictors. Motivated by this finding, we conducted two parts follow up analysis to further explore the role of healthcare resources and how predictor importance shifts across life stages.

[*Part 1: Healthcare resources and geographic patterns*]{.underline}

First, we assessed whether the geographic distribution of healthcare resources mirrors the spatial distribution of SRH. Using our GIS visualizations, we compared provincial patterns in SRH with hospital density and the number of healthcare professionals per 10,000 people (NBS, 2018). This analysis evaluates whether provinces with greater healthcare capacity also tend to show better average self-rated health, and it helps identify potential mismatches where resource availability does not align with observed health needs.

[*Part 2: How predictors change across age groups*]{.underline}

Second, we examined whether the drivers of SRH prediction differ by age. We divided the sample into four age quartiles, younger, young to middle, middle to older, and elderly, and re estimated importance within three grouped domains:

1.  Demographic: age, sex, marital status, living with a partner, number of family members, and religion
2.  Socioeconomic: income, pension, farming status, living area, and real estate ownership
3.  Healthcare resources: hospital density per 10,000, healthcare professionals per 10,000, and medical insurance coverage

Because the quartiles are defined by the sample distribution, subgroup sizes are balanced, which improves comparability of importance scores across age groups. Given the balanced sampling design of CHARLS, these quartiles also provide a useful approximation of life course stages, including younger adults in the CHARLS frame, near retirement adults, retirees, and older elderly (Zhao et al., 2020).

Across analyses, we observed two consistent patterns. First, SRH and healthcare resources show aligned geographic patterns in the visualizations, but healthcare resources are also closely correlated with broader socioeconomic development at the provincial level (NBS, 2018). Second, as age increases, healthcare resource indicators become relatively more important than socioeconomic variables for predicting SRH, while demographic factors also rise in importance. This suggests that for older adults, access to healthcare capacity and broader support conditions may matter at least as much as individual socioeconomic position in shaping perceived health status, consistent with prior work emphasizing the multifaceted determinants of SRH (Clark et al., 2021).

4.  Deep-dive into the final model

```{r}
# by checking the variable importance of the random forest model, 
# we can see that age and hospital resources are ranked very high.
knitr::include_graphics("graph/importance_rf.png")

# hospital resources by province, compared with health status
## density of hospitals (per 10,000 population)
prov_hosp <- data_train |>
  group_by(province) |>
  summarise(
    hosp_10k_mean = mean(as.numeric(hosp_10k), na.rm = TRUE),
    .groups = "drop"
  )

cn_hosp <- cn |>
  left_join(prov_hosp, by = "province")

ggplot(cn_hosp,
       aes(x = long, y = lat, group = group, fill = hosp_10k_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),  #  red~low, high~green
    na.value = "grey90",
    name = "hospital density（per 10,000 population）"
  ) +
  labs(
    title = "Hospital density by province in 2018 (hospitals per 10,000 people)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_hospital.png")

## density of health professionals (per 10,000 population)
prov_staff <- Final_2018Merged |>
  group_by(province) |>
  summarise(
    staff_10k_mean = mean(as.numeric(staff_10k), na.rm = TRUE),
    .groups = "drop"
  )
 
cn_staff <- cn |>
  left_join(prov_staff, by = "province")

ggplot(cn_staff,
       aes(x = long, y = lat, group = group, fill = staff_10k_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),
    na.value = "grey90",
    name = "Healthcare personnel density (per 10,000 people)"
  ) +
  labs(
    title = "Healthcare personnel density (professionals per 10,000 people)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_medical_professinals.png")

# check variable importance by different age groups
## divide variables into different groups
var_groups <- list(
  demographic = c("living_area", "marital_status", "bg002_w4", "cb050_w3", "bf006_w4_5_1", "male", "age"),
  socio_economic = c("fa002_w4", "fn002_w4", "ga001", "ga002", "ha000_w4_0"),
  healthcare_resources = c("hosp_10k", "staff_10k", "ea001_w4_s12")
)

## divide the dataset into different groups of age per sample distribution
summary(data$age)
data_train_age <- data_train |>
  mutate(age_group = case_when(
    age < 53 ~ "Younger",
    age >= 53 & age < 61 ~ "Young-Middle",
    age >= 61 & age < 68 ~ "Middle-Elder",
    age >= 68 ~ "Elderly")) |>
  filter(!is.na(age))

## fit for different age groups
fit_young <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Younger"))
fit_ym <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Young-Middle"))
fit_me <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Middle-Elder"))
fit_elderly <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Elderly"))

## extract importance and label for each group
vi_young   <- vi(extract_fit_parsnip(fit_young)) |> 
  mutate(age_group = "Younger")
vi_ym  <- vi(extract_fit_parsnip(fit_ym)) |> 
  mutate(age_group = "Young-Middle")
vi_me  <- vi(extract_fit_parsnip(fit_me)) |> 
  mutate(age_group = "Middle-Elder")
vi_elderly <- vi(extract_fit_parsnip(fit_elderly)) |>
  mutate(age_group = "Elderly")

## combine importance scores, add variable category, sum up importance scores
all_age_importance <- bind_rows(vi_young, vi_ym, vi_me, vi_elderly) |>
  mutate(category = case_when(
    Variable %in% var_groups$demographic ~ "Demographic",
    Variable %in% var_groups$socio_economic ~ "Socio-Economic",
    Variable %in% var_groups$healthcare_resources ~ "Healthcare Resources")) |>
  group_by(age_group, category) |>
  summarize(importance = sum(Importance, na.rm = TRUE)) |>
  filter(!is.na(category)) |>
  mutate(age_group = factor(age_group, 
                            levels = c("Younger", "Young-Middle", "Middle-Elder", "Elderly")))

## plotting for variable importance by age group
ggplot(all_age_importance, aes(x = age_group, y = importance, fill = category)) +
  geom_col(position = "dodge") +
  labs(
    title = "Importance of Variable Categories by Age Group") +
  theme_minimal() +
  theme(legend.position = "top")

ggsave(filename = "graph/importance_rf_age.png")
```

# Summary

## **Methodological Strengths**

This project has several methodological strengths.

First, it integrates a GIS based mapping workflow using the chinamap package, which provides standardized mappings between provincial identifiers and administrative boundaries in China. This allows province level measures of GDP, healthcare resources, which are out-sample information, as well as income, and average self-rated health to be consistently linked to geographic units and visualized on a national map. The resulting spatial visualizations add an interpretable descriptive layer that complements the individual level predictive analysis.

Second, the project adopts an age stratified modeling approach to examine heterogeneity in predictors across life stages. We divide the sample into four age groups, fit models within each group, and summarize the relative importance of grouped predictor domains. This design supports the project’s research question by making it possible to compare whether socioeconomic factors, demographic factors, or healthcare context contributes more to prediction in different age segments. The approach also aligns with prior work emphasizing that determinants of self-rated health can vary across the life course (Clark et al., 2021; Zhang et al., 2021).

Third, the project evaluates alternative outcome constructions by transforming the original five category self-rated health measure into both a multi category classification target and a binary classification target. Comparing results across outcome definitions functions as a robustness check and clarifies how predictive performance and variable importance change when the outcome is simplified for interpretability.

## **Limitation**

Several limitations should be acknowledged.

First, missing values are present in several variables, which reduces the effective sample size and may affect model stability. Although standard cleaning procedures are applied, missingness can still introduce bias if it is systematically related to health status or socioeconomic conditions.

Second, some contextual covariates are available only at the provincial level and are therefore coarse in spatial resolution. Indicators such as hospitals or healthcare professionals per 10,000 people can mask substantial within province heterogeneity, especially in large and economically diverse provinces. As a result, province level variables may capture broad development patterns but may not fully represent the local healthcare access that individuals face.

Third, the analysis is cross sectional and focuses on a single pre pandemic year. The models describe associations under 2018 conditions and do not capture health trajectories over time. Therefore, results should not be interpreted as causal effects or as evidence about long run health dynamics.

Finally, because self-rated health is a subjective measure, it may reflect differences in reporting behavior in addition to differences in underlying health. This is particularly relevant when comparing groups or regions if expectations and reference points differ, even when objective health burdens are similar (Qi, 2014).

## **Significance**

The analysis identifies clear regional differences in economic conditions and average self-rated health, with more developed coastal provinces generally showing higher income levels and better average self-rated health than inland regions. At the individual level, the predictive models achieve meaningful held out performance, suggesting that routinely observed demographic and socioeconomic characteristics contain substantial information about perceived health status. This finding is consistent with prior evidence that self-rated health is systematically related to social and economic conditions and can be predicted using standard survey features (Clark et al., 2021; Fan & He, 2022).

From a policy perspective, the results suggest that administrative and survey variables that are already widely collected can support approximate screening of population health risk, reducing reliance on frequent or costly health assessments in large scale monitoring. Predictive models of this kind can help governments and health agencies identify populations that are more likely to report poor health and prioritize monitoring, outreach, or preventive interventions.

In addition, the age stratified results highlight meaningful heterogeneity in predictor importance, implying that the most informative signals of health risk differ across stages of later life. This supports the value of age targeted strategies for health planning and resource allocation, especially in rapidly aging settings.
