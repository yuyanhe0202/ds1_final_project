---
title: "Final Project"
author: "He_Huang_Yang_Yu"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
execute:
  warning: false
  message: false
embed-resources: true
---

# Background

China is experiencing rapid population aging, raising growing concerns about how to assess and anticipate health risks among middle-aged and older adults. While individual health conditions are typically measured through surveys or clinical assessments, such approaches are time-consuming and costly at scale. An alternative perspective is to ask whether individual health status can be reasonably inferred from information that is already observable at more aggregated or administrative levels, such as demographic characteristics, socioeconomic conditions, and regional context. Self-reported health is a widely used indicator that reflects both physical health and broader living conditions, making it a suitable outcome for exploring this predictive possibility.

Using data from the 2018 wave of the China Health and Retirement Longitudinal Study (CHARLS), this project adopts a predictive approach to examine self-reported health among middle-aged and older adults in China. The analysis focuses on assessing how accurately individual self-reported health can be predicted using observable demographic, socioeconomic, and health-related characteristics. The central research question is: which individual characteristics are most informative for predicting self-reported health, and how well can overall health status be predictedusing variables that are commonly available in survey or administrative data?

The analysis begins with exploratory data analysis (EDA) to describe the distribution of self-reported health and key covariates. In this stage, the project visualizes provincial-level GDP, average self-reported health, and income measures. These visualizations serve as a simple descriptive check, based on the common observation that regions with stronger economic conditions tend to exhibit better average health outcomes. The spatial patterns help establish an intuitive baseline for understanding regional disparities before moving to individual-level prediction.

Building on these descriptive patterns, the project adopts a predictive framework to assess how well individual self-reported health can be predicted using observable demographic, socioeconomic, and access to healthcare variables. Supervised machine learning methods are applied to train multiple models and compare them using out-of-sample performance metrics. This approach allows for an evaluation of both overall predictive accuracy and the relative importance of different types of predictors.

Overall, the project combines exploratory spatial analysis with predictive modeling to examine whether individual health risks can be inferred from information that is already available at broader levels, such as household registration, socioeconomic status, or provincial context. From a policy perspective, this approach highlights the potential to approximate individual health conditions without relying solely on extensive field surveys or frequent individual-level data collection. In the context of rapid population aging in China, such predictive insights may help governments identify high-risk populations more efficiently and support more timely health planning and resource allocation at the regional level.

# Data Source and Outcome Definition

The analysis uses data from the 2018 wave of the China Health and Retirement Longitudinal Study (CHARLS), a nationally representative survey of Chinese residents aged 45 and above. CHARLS employs a stratified, multi-stage probability sampling design and provides survey weights to ensure representativeness of the target population. The 2018 wave covers 28 provinces in China, excluding Ningxia, Tibet, and Hainan from the sampling frame. In addition, provincial-level GDP and healthcare resource data from the National Bureau of Statistics of China are merged with the cleaned CHARLS dataset to construct a unified analytical dataset.

The analysis focuses on the 2018 wave rather than the 2020 wave because the latter coincides with the COVID-19 pandemic, during which self-reported health may reflect short-term, system-wide shocks. Using 2018 data allows the study to examine individual health perceptions under relatively stable social and health-system conditions.

The outcome of interest is self-reported health status, measured by the CHARLS survey variable da002. Respondents are asked to rate their overall health on a five-point ordinal scale: very good, good, fair, poor, or very poor. This variable captures individuals’ subjective assessment of their general health and is widely used in studies of aging and population health. For the purpose of predictive modeling, da002 is transformed into two alternative target variables: a three-category outcome that groups responses into good, medium, and bad health, and a binary outcome that classifies respondents into good versus bad health.

# Variable selection rationale

The objective of this analysis is to predict individual health status in a way that is informative for resource allocation, rather than for detailed household-level diagnosis. From a central-government perspective, the goal is to assess health needs without relying on costly and time-intensive household surveys. Accordingly, the model relies on general demographic and socio-economic characteristics that are routinely collected through administrative systems and are plausibly correlated with health outcomes. These include age, gender, marital status, living area (urban–rural classification), employment and retirement status, income and pension receipt, health insurance coverage, and number of children. These variables capture key life-course, labor market, and institutional dimensions that shape health risks and access to care, while remaining broadly observable and policy-relevant. In addition, the analysis incorporates province-level health resource indicators, specifically the number of hospitals and healthcare professionals per 10k population, to account for regional variation in healthcare supply.

# Data cleaning and variable construction

The raw CHARLS 2018 data were cleaned and transformed to produce a model-ready dataset suitable for machine-learning workflows. Variables imported with survey value labels were explicitly converted to appropriate formats to avoid unintended numeric interpretations. Categorical variables such as living area and marital status were converted to factor variables using their original survey labels, ensuring they would be treated as nominal predictors in the modeling stage. Binary survey responses (e.g., employment status, income receipt etc.), which were originally coded numerically, were recoded into consistent 0/1 indicators based on documented response categories. Original variables were preserved where necessary, and transformed variables were created explicitly to maintain transparency and reproducibility. This pre-processing strategy ensures that predictors are compatible with relevant machine learning pipelines such as dummy-variable generation.

1.  Import data, select variables, convert to variables, cleaning variables

```{r}
#install.packages("remotes")
#remotes::install_github("GuangchuangYu/chinamap")
library(tidyverse)
library(tidymodels)
library(vip)
library(chinamap)
library(readxl)

load("data/Final_2018Merged.RData")

# da002: Self-Reported Health Status
# cd001_w4_1_: Who Live with XConParName[1]
# be002: Have a Partner Living Together
# bb001_w3_2: Location of Residential Address
# be001: Marital Status
# bf006_w4_5_1: The Number of Children Under 18
# bg002_w4: Religious Beliefs
# fa002_w4: Nonfarm Work (for at Least One Hour Last Month) or Not
# ga001: Receive Wage and Bonus Income
# ga002: How Much Receive
# fn002_w4: Receive/Participate Government/Institutions/Firm Pension
# ha000_w4_0: Number of Houses
# ea001_w4_s12: No Medical Insurance
# cb050_w3: Number of Children
# hosp_10k: Number of hospitals per 10k population
# staff_10k: Number of health professionals per 10,000 population


# select only the variables needed
data <- Final_2018Merged |>
  select(ID, da002, ba000_w2_3, ba004_w3_1, cd001_w4_1_, bb001_w3_2, be001, bf006_w4_5_1, bg002_w4, fa002_w4, ga001, ga002, fn002_w4, ha000_w4_0, ea001_w4_s12, cb050_w3, hosp_10k, staff_10k, INDV_weight_ad2, province) |>
  filter(!is.na(da002)) |>
  mutate(living_area = haven::as_factor(bb001_w3_2)) |>
  mutate(marital_status = haven::as_factor(be001)) |>
  mutate(male = case_when(
    as.numeric(ba000_w2_3) == 1 ~ 1,
    as.numeric(ba000_w2_3) == 2 ~ 0)) |>
  mutate(age = 2018 - ba004_w3_1) |>
  mutate(bg002_w4 = case_when(
    as.numeric(bg002_w4) == 1 ~ 1,
    as.numeric(bg002_w4) == 2 ~ 0)) |>
  mutate(fa002_w4 = case_when(
    as.numeric(fa002_w4) == 1 ~ 1,
    as.numeric(fa002_w4) == 2 ~ 0)) |>
  mutate(ga001 = case_when(
    as.numeric(ga001) == 1 ~ 1,
    as.numeric(ga001) == 2 ~ 0)) |>
  mutate(fn002_w4 = case_when(
    as.numeric(fn002_w4) == 1 ~ 1,
    as.numeric(fn002_w4) == 2 ~ 0)) |>
  mutate(ea001_w4_s12 = case_when(
    as.numeric(ea001_w4_s12) == 0 ~ 1,
    as.numeric(ea001_w4_s12) == 12 ~ 0)) |>
  mutate(health_cat = case_when(
    as.numeric(da002) == 1 ~ "good",
    as.numeric(da002) == 2 ~ "good",
    as.numeric(da002) == 3 ~ "bad",
    as.numeric(da002) == 4 ~ "bad",
    as.numeric(da002) == 5 ~ "bad"))

```

# Machine learning methodology

To investigate the drivers of health status, we implemented a machine learning pipeline that integrated individual survey weights to ensure national representativeness. The data was split into an 80% training set and a 20% test set, with model performance optimized through 10-fold cross-validation. We evaluated both LASSO and Random Forest architectures across two distinct frameworks: continuous regression using the 5-point survey scale and categorical classification. In the classification approach, we initially categorized health status into three levels (Bad, Fair, and Good), but this yielded a low accuracy of approximately 0.50. Reflecting Chinese cultural traditions where "Fair" is often a polite proxy for "Not Good," we re-categorized the outcome into a binary Good/Bad classification, which significantly improved accuracy.

2.0 Get data

```{r}
set.seed(0202)

# Get the clean data, remove redundant variables, call weighting
data_clean <- data %>%
  mutate(weight_idv = importance_weights(INDV_weight_ad2)) |>
  select(-bb001_w3_2, -be001, -ba000_w2_3, -ba004_w3_1, -ID, -INDV_weight_ad2) |>
  filter(!is.na(weight_idv))

## Split data
data_split <- initial_split(data = data_clean, prop = 0.8)
data_train <- training(x = data_split)
data_test <- testing(x = data_split)

```

2.0 Continued: Exploratory Data Analysis: presenting China economic status and health status

```{r}
# 1. China GDP by province 
# GDP information is not from the dataset we use; just to present a general idea of China's economic status
## read GDP file, merge into map
GDP <- read_excel("data/GDP.xls", sheet = "Sheet1")

cn <- get_map_china()

cn_gdp <- cn |>
  left_join(GDP, by = "province")

## map
ggplot(cn_gdp,
                aes(x = long, y = lat, group = group, fill = gdp_2018)) +
  geom_polygon(color = "black", linewidth = 0.2) + 
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),
    na.value = "grey90",
    name = "GDP in 2018"
  ) +
  labs(
    title = "Each province's GDP in 2018"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_gdp.png")

# 2. distribution of individual income
## select a series of individual income variables
income_vars <- c("ga002")

## extract these values about individual annual income
income_mat <- data_train[, income_vars]

## For each sample, sum the income to obtain the total personal income.
person_income <- rowSums(as.matrix(income_mat), na.rm = TRUE)

## calculate annual individual income by province
prov_income <- data_train |>
  mutate(person_income = person_income) |>
  group_by(province) |>
  summarise(
    mean_income = mean(person_income, na.rm = TRUE),
    .groups = "drop"
  )

## merge data into China map
cn_income <- cn |>
  left_join(prov_income, by = "province")

## map of annual individual income by province
ggplot(cn_income,
       aes(x = long, y = lat, group = group, fill = mean_income)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),  # red~low, high~green
    na.value = "grey90",
    name = "Average annual individual income"
  ) +
  labs(
    title = "Average annual individual income in each province in 2018"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_income.png")

# 3. average self-reported health status by province

## Change da002 from haven_labelled to numeric
data_train <- data_train |>
  mutate(
    province = recode(
      province,
      "北京"   = "北京市",
      "广西省" = "广西壮族自治区"  #manually change 2 names into official ones
    )
  )

##. Calculate the mean of da002 by province
prov_da <- data_train |>
  group_by(province) |>
  summarise(
    da002_mean = mean(da002, na.rm = TRUE)
  ) |>
  ungroup()

## merge province-level data into China map
cn_da <- cn |>
  left_join(prov_da, by = "province")

## map of average da002 among all provinces
ggplot(cn_da,
            aes(x = long, y = lat, group = group, fill = da002_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("darkgreen", "yellow", "red"),  #red~low, high~green
    na.value = "grey90"
  ) +
  labs(
    title = "Average self-reported health in each province（da002）",
    fill  = "Average self-reported health (da002)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_health.png")

```

2.1 Using regression pipelines

```{r}
# create a recipe
data_rec <- 
  recipe(da002 ~ ., data = data_train) %>%
  step_rm(health_cat, province) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

# v-fold: using this folds for all remaining models
folds <- vfold_cv(data = data_train, v = 10, repeats = 1)

# Lasso prediction
## create a tuning grid for lasso regularization, varying the regularization penalty
lasso_grid <- grid_regular(penalty(), levels = 10)

## Lasso specification
lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet")

## Lasso workflow
lasso_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lasso_mod) %>%
  add_case_weights(weight_idv)

## fit
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

## Calculate RMSE
lasso_rmse <- lasso_cv %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "rmse")

## Plot RMSE
lasso_rmse |>
  group_by(id) |>
  summarize(RMSE = mean(.estimate)) |>
  ggplot(aes(x = id, y = RMSE)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "RMSE",
    title = "Lasso RMSE Across Penalty Values"
  ) +
  theme_minimal()

## Mean RMSE across 10 folds
mean(lasso_rmse$.estimate)


# ----------Random Forest prediction--------------
rf_mod <- rand_forest() |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

## Random forest workflow
rf_wf <- workflow() |>
  add_recipe(data_rec) |>
  add_model(rf_mod) |>
  add_case_weights(weight_idv)

## fit
rf_resamples <- rf_wf |>
  fit_resamples(resamples = folds)

## Calculate RMSE
rf_rmse <- rf_resamples %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "rmse")

## Plot RMSE
rf_rmse |>
  ggplot(aes(x = id, y = .estimate)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "RMSE",
    title = "Random Forest RMSE Across Penalty Values"
  ) +
  theme_minimal()

## Mean RMSE across 10 folds
mean(rf_rmse$.estimate)


# --------Model choose, final fit and check variable importance
# Random Forest model has the lower RMSE in the regression approach; 
# we would therefore check the best fit model using the RF model

## select the best model based on the "rmse" metric
rf_best <- rf_resamples %>%
  select_best(metric = "rmse")

# finalize random forest workflow and the best model 
rf_final <- finalize_workflow(rf_wf, rf_best) %>% 
  fit(data = data_train)

## important predictors for rf model
rf_final |>
  extract_fit_parsnip() |>
  vip() + 
  labs(title = "Variable Importance: Random Forest Model") +
  theme_minimal()

ggsave(filename = "graph/importance_rf.png")

```

2.2 Using classification pipelines

```{r}
# Treat health status as bad and good
# create a new recipe
data_rec_cat <- 
  recipe(health_cat ~ ., data = data_train) %>%
  step_rm(da002, province) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

# --------Lasso specification------
lasso_mod_cat <- multinom_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

## Lasso workflow
lasso_wf_cat <- workflow() %>%
  add_recipe(data_rec_cat) %>%
  add_model(lasso_mod_cat) %>%
  add_case_weights(weight_idv)

## fit
lasso_cv_cat <- lasso_wf_cat %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid
  )

## check accuracy
lasso_acc <- lasso_cv_cat %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy")

## Plot accuracy
lasso_acc |>
  group_by(id) |>
  summarize(accuracy = mean(.estimate)) |>
  ggplot(aes(x = id, y = accuracy)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "accuracy",
    title = "Lasso Accuracy Across Penalty Values"
  ) +
  theme_minimal()

mean(lasso_acc$.estimate)

# --------Random forest-----------
## Random Forest model call
rf_mod_cat <- rand_forest() |>
  set_mode(mode = "classification") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

## workflow
rf_wf_cat <- workflow() |>
  add_recipe(data_rec_cat) |>
  add_model(rf_mod_cat) |>
  add_case_weights(weight_idv)

## fit
rf_resamples_cat <- rf_wf_cat |>
  fit_resamples(resamples = folds)

## Calculate RMSE
rf_acc <- rf_resamples_cat %>%
  collect_metrics(summarize = FALSE) %>%
  filter(.metric == "accuracy")

## Plot RMSE
rf_acc |>
  ggplot(aes(x = id, y = .estimate)) +
  geom_point() +
  labs(
    x = "Fold id",
    y = "Accuracy",
    title = "Random Forest Accuracy Across Penalty Values"
  ) +
  theme_minimal()

## Mean Accuracy across 10 folds
mean(rf_acc$.estimate)

# --------Model choose, final fit and check variable importance
# Lasso model has the higher accuracy in the classification approach; 
# we would therefore check the best fit model using the Lasso model

## select the best model based on the "accuracy" metric
lasso_best <- lasso_cv_cat %>%
  select_best(metric = "accuracy")

## finalize lasso workflow and the best model 
lasso_final <- finalize_workflow(
  lasso_wf_cat,
  parameters = lasso_best
)

## fit to the training data and extract coefficients
lasso_coefs <- lasso_final %>%
  fit(data = data_train) %>%
  extract_fit_parsnip() %>%
  vi()

## check important predictors and plot
lasso_coefs |>
  mutate(Variable = reorder(Variable, Importance)) |>
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  labs(
    title = "Variable Importance: Lasso Model") +
  facet_grid(~ Sign) +
  theme_minimal()

ggsave(filename = "graph/importance_lasso.png")

```

# Final model choose

In the regression analysis, which preserved the original granularity of the 5-point health scale, the Random Forest model outperformed the LASSO regression by achieving a lower Root Mean Square Error (RMSE). Conversely, in the classification task—where health status was grouped into discrete "good" and "bad" categories, the LASSO model yielded slightly higher accuracy. While both modeling strategies produced broadly consistent results, the classification approach relies on a subjective threshold for health categorization that may sacrifice nuance or introduce bias. Therefore, to ensure the most robust and objective estimation of health outcomes, we selected the Random Forest regression as our final model for evaluation against the test dataset.

3.  Fit the final model, check result

```{r}
# fit on test data
test_pred <- predict(rf_final, data_test)

# getting rmse
test_pred <- data_test %>%
  select(da002) %>%
  bind_cols(test_pred)

rmse(test_pred, truth = da002, estimate = .pred)

```

## Deep-dive into the final model

Following the selection of the Random Forest as our final model, we observed that age and healthcare resources emerged as the most significant predictors of health status. Based on this, we conducted a two-part follow-up analysis to investigate the age, healthcare resources and their relationship with health status.

First, we examined whether the geographical distribution of healthcare resources follows a similar pattern to general health status. This analysis seeks to determine if areas with higher resource density (hospital and staff availability) correspond to regions with superior health outcomes, or if significant gaps exist where resource allocation fails to match the population's health needs.

Second, we analyzed how the drivers of health shift across different life stages. We divided the sample into four quartiles — Younger, Young to middle, Middle to elder, and Elderly — and re-evaluated importance within three categorized domains: Demographic: Age, sex, marital status, living with a partner, number of family members, and religion. Socio-economic: Income, pension, farming status, living area (urban/rural), and real-estate ownership. Healthcare resources: Hospital density per 10k, healthcare professionals per 10k, and medical insurance coverage.

The four groups of age were divided per sample distribution. Similar subgroup size ensures the comparability of important scores across group, and thanks to the balanced sampling of CHARLS dataset, the four groups are also good representatives of intuitive population stratification of younger, close to retirement, retired and elderly.

From the results, 1. Health status and healthcare resources are indeed related from the GIS visualization we generated. But still, healthcare resources are very tightly bundled with socio-economic level. 2. We've found that as the group ages, healthcare resources would replace socio-economic as the most important predictor of health status. The importance of demographic variables also arises. We could probably conclude therefore that systematic support from society and family are more important than economic status in terms of physical and mental health for elderly.

4.  Deep-dive into the final model

```{r}
# by checking the variable importance of the random forest model, 
# we can see that age and hospital resources are ranked very high.
knitr::include_graphics("graph/importance_rf.png")

# hospital resources by province, compared with health status
## density of hospitals (per 10,000 population)
prov_hosp <- data_train |>
  group_by(province) |>
  summarise(
    hosp_10k_mean = mean(as.numeric(hosp_10k), na.rm = TRUE),
    .groups = "drop"
  )

cn_hosp <- cn |>
  left_join(prov_hosp, by = "province")

ggplot(cn_hosp,
       aes(x = long, y = lat, group = group, fill = hosp_10k_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),  #  red~low, high~green
    na.value = "grey90",
    name = "hospital density（per 10,000 population）"
  ) +
  labs(
    title = "Hospital density by province in 2018 (hospitals per 10,000 people)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_hospital.png")

## density of health professionals (per 10,000 population)
prov_staff <- Final_2018Merged |>
  group_by(province) |>
  summarise(
    staff_10k_mean = mean(as.numeric(staff_10k), na.rm = TRUE),
    .groups = "drop"
  )
 
cn_staff <- cn |>
  left_join(prov_staff, by = "province")

ggplot(cn_staff,
       aes(x = long, y = lat, group = group, fill = staff_10k_mean)) +
  geom_polygon(color = "black", size = 0.1) +
  coord_map() +
  scale_fill_gradientn(
    colours = c("red", "yellow", "darkgreen"),
    na.value = "grey90",
    name = "Healthcare personnel density (per 10,000 people)"
  ) +
  labs(
    title = "Healthcare personnel density (professionals per 10,000 people)"
  ) +
  theme_void() +
  theme(
    legend.position = "right",
    plot.title      = element_text(hjust = 0.5)
  )
ggsave(filename = "graph/china_medical_professinals.png")

# check variable importance by different age groups
## divide variables into different groups
var_groups <- list(
  demographic = c("living_area", "marital_status", "bg002_w4", "cb050_w3", "bf006_w4_5_1", "male", "age"),
  socio_economic = c("fa002_w4", "fn002_w4", "ga001", "ga002", "ha000_w4_0"),
  healthcare_resources = c("hosp_10k", "staff_10k", "ea001_w4_s12")
)

## divide the dataset into different groups of age per sample distribution
summary(data$age)
data_train_age <- data_train |>
  mutate(age_group = case_when(
    age < 53 ~ "Younger",
    age >= 53 & age < 61 ~ "Young-Middle",
    age >= 61 & age < 68 ~ "Middle-Elder",
    age >= 68 ~ "Elderly")) |>
  filter(!is.na(age))

## fit for different age groups
fit_young <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Younger"))
fit_ym <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Young-Middle"))
fit_me <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Middle-Elder"))
fit_elderly <- rf_final |> 
  fit(data = filter(data_train_age, age_group == "Elderly"))

## extract importance and label for each group
vi_young   <- vi(extract_fit_parsnip(fit_young)) |> 
  mutate(age_group = "Younger")
vi_ym  <- vi(extract_fit_parsnip(fit_ym)) |> 
  mutate(age_group = "Young-Middle")
vi_me  <- vi(extract_fit_parsnip(fit_me)) |> 
  mutate(age_group = "Middle-Elder")
vi_elderly <- vi(extract_fit_parsnip(fit_elderly)) |>
  mutate(age_group = "Elderly")

## combine importance scores, add variable category, sum up importance scores
all_age_importance <- bind_rows(vi_young, vi_ym, vi_me, vi_elderly) |>
  mutate(category = case_when(
    Variable %in% var_groups$demographic ~ "Demographic",
    Variable %in% var_groups$socio_economic ~ "Socio-Economic",
    Variable %in% var_groups$healthcare_resources ~ "Healthcare Resources")) |>
  group_by(age_group, category) |>
  summarize(importance = sum(Importance, na.rm = TRUE)) |>
  filter(!is.na(category)) |>
  mutate(age_group = factor(age_group, 
                            levels = c("Younger", "Young-Middle", "Middle-Elder", "Elderly")))

## plotting for variable importance by age group
ggplot(all_age_importance, aes(x = age_group, y = importance, fill = category)) +
  geom_col(position = "dodge") +
  labs(
    title = "Importance of Variable Categories by Age Group") +
  theme_minimal() +
  theme(legend.position = "top")

ggsave(filename = "graph/importance_rf_age.png")
```

# Summary

This project implements a predictive workflow that links exploratory spatial analysis with machine learning models to assess patterns in self-reported health. Provincial-level visualizations of GDP, income, and average self-reported health are first used to summarize broad regional patterns. These descriptive results provide context for the subsequent supervised classification models, which are evaluated using out-of-sample performance and variable importance across different outcome definitions and age groups.

## Methodological Strengths

The project has several methodological strengths. First, the project incorporates a GIS-based mapping workflow using the chinamap package, which provides standardized mappings between provincial identifiers and China’s administrative boundaries. This allows province-level measures of GDP, income, and average self-reported health to be accurately linked to geographic units and visualized on a national map. The resulting spatial visualizations add a structured descriptive layer that complements the individual-level predictive analysis.

Second, the project adopts a modeling approach stratified by age group, motivated by prior literature. The analysis stratifies the sample into four age groups, fits models within each group, and visualizes the aggregated importance of variable domains. These visualizations facilitate comparison of which types of factors are most informative for predicting self-reported health across different segments of the middle-aged and older population.

Finally, the project explores alternative outcome constructions by transforming the original five-category self-reported health variable into both a multi-category and a binary classification target. This allows for robustness checks across classification settings and demonstrates how prediction performance and variable importance change when the outcome definition is simplified.

## Limitation

Several limitations should be acknowledged. First, a nontrivial number of variables contain missing values, which reduces the effective sample size and may affect model stability. While standard data cleaning procedures are applied, missingness may still introduce bias if it is systematically related to health status or socioeconomic conditions.

Second, some contextual variables are only available at the provincial level and are relatively coarse in spatial resolution. Covariates such as hospitals or health resources per 10,000 people may mask substantial within-province heterogeneity, particularly in large and economically diverse provinces. As a result, regional variables may have limited predictive power at the individual level.

Finally, the analysis is cross-sectional and focuses on a single pre-pandemic year. The models capture associations relevant to 2018 conditions but do not account for dynamic health trajectories or changes over time. Consequently, the results should not be interpreted as evidence about long-term health evolution or causal effects.

## Significance

The analysis reveals clear regional disparities in economic conditions and average self-reported health, with more developed coastal provinces generally exhibiting higher income levels and better average health than inland regions. At the individual level, the predictive models achieve meaningful out-of-sample performance, indicating that observable demographic and socioeconomic characteristics contain substantial information about perceived health status.

From a policy perspective, the results demonstrate that routinely collected demographic and socioeconomic data contain sufficient information to approximate individual health risks, reducing reliance on frequent or costly health assessments and helping save both time and financial resources in large-scale health monitoring. Predictive models of this kind can help governments and health agencies identify populations that are more likely to report poor health and prioritize monitoring or preventive interventions. Moreover, the pronounced age heterogeneity in predictor importance underscores the value of age-targeted health strategies, as the types of information most relevant for assessing health risks differ systematically across stages of later life.
